{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# symbolic_representers\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp symbolic_representers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import sglang as sgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@sgl.function\n",
    "def image_to_text(s, image_path, representation_description):\n",
    "    s += sgl.user(sgl.image(image_path) + representation_description)\n",
    "    s += sgl.assistant(sgl.gen(\"answer\"))\n",
    "\n",
    "class ImageRepresenter:\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_path=\"liuhaotian/llava-v1.5-7b\",\n",
    "            tokenizer_path=\"llava-hf/llava-1.5-7b-hf\",\n",
    "            representation_description=\"Please describe this image in great detail\"\n",
    "        ):\n",
    "        self.runtime = sgl.Runtime(\n",
    "            model_path=model_path,\n",
    "            tokenizer_path=tokenizer_path\n",
    "        )\n",
    "        sgl.set_default_backend(self.runtime)\n",
    "        self.representation_description = representation_description\n",
    "\n",
    "    def convert_to_text(self, images, max_new_tokens = 64):\n",
    "        images = [images] if isinstance(images, str) else images\n",
    "        states = image_to_text.run_batch(\n",
    "            [\n",
    "                {\"image_path\": image, \"representation_description\": desc}\n",
    "                for image, desc in\n",
    "                zip(images, [self.representation_description] * len(images))\n",
    "            ],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "        return [s[\"answer\"].lstrip() for s in states]\n",
    "\n",
    "    def shutdown(self):\n",
    "        self.runtime.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_representer = ImageRepresenter()\n",
    "# texts = image_representer.convert_to_text(\"images/dog.jpeg\")\n",
    "# image_representer.shutdown()\n",
    "# texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VideoRepresenter: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class WebSiteRepresenter:\n",
    "    \"\"\"\n",
    "    Based on WebArena: https://arxiv.org/pdf/2307.13854.pdf\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=0 python3 -m sglang.launch_server --model-path liuhaotian/llava-v1.6-mistral-7b --tokenizer-path liuhaotian/llava-v1.6-mistral-7b --port 30000\n",
    "# python -m llava.serve.sglang_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --sgl-endpoint http://127.0.0.1:30000\n",
    "# python -m sglang.launch_server --model-path THUDM/cogvlm-chat-hf --port 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
