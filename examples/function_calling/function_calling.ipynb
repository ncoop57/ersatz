{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f83295",
   "metadata": {},
   "source": [
    "# Creating generalizable function calling chat models with synthetic data\n",
    "\n",
    "> How to write great nbdev notebooks\n",
    "\n",
    "- order: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5048e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from ersatz.interactions import Conversation\n",
    "from ersatz.symbolic_representers import WebSiteRepresenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3460349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "gpt4 = dspy.OpenAI(model=\"gpt-4-1106-preview\", api_key='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', max_tokens=4000, model_type=\"chat\")\n",
    "gpt_turbo = dspy.OpenAI(model=\"gpt-3.5-turbo\", api_key='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', max_tokens=4000, model_type=\"chat\")\n",
    "\n",
    "lms = [\n",
    "    {\"name\": \"GPT-4\", \"lm\": gpt4},\n",
    "       {\"name\": \"GPT-3.5-Turbo\", \"lm\": gpt_turbo},]\n",
    "# export OPENAI_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce865bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20157/1922281202.py:17: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @pydantic.validator('call')\n"
     ]
    }
   ],
   "source": [
    "from dspy import InputField, OutputField, Signature\n",
    "from dspy.functional import TypedPredictor\n",
    "import pydantic\n",
    "\n",
    "class Function(pydantic.BaseModel):\n",
    "    name: str # the name of the function\n",
    "    parameters: dict[str, str] # the parameters of the function with their types\n",
    "    docstring: str # the docstring of the function\n",
    "    return_type: str # the return type of the function\n",
    "\n",
    "class Functions(pydantic.BaseModel):\n",
    "    functions: list[Function]\n",
    "\n",
    "class FunctionCall(pydantic.BaseModel):\n",
    "    call: str\n",
    "    \n",
    "    @pydantic.validator('call')\n",
    "    def check_syntax(cls, v):\n",
    "        try:\n",
    "            # Attempt to compile the code snippet\n",
    "            compile(v, \"<string>\", \"exec\")\n",
    "        except SyntaxError as e:\n",
    "            # If a SyntaxError is raised, the code is not syntactically valid\n",
    "            raise ValueError(f\"Code is not syntactically valid: {e}\")\n",
    "\n",
    "        return v\n",
    "    \n",
    "class FunctionCalls(pydantic.BaseModel):\n",
    "    calls: list[FunctionCall]\n",
    "\n",
    "class FunctionsSignature(Signature):\n",
    "    topic: str = InputField(desc='The topic that the new functions should be related to.')\n",
    "    functions: Functions = OutputField(desc='The list of python functions that correspond to the topic.')\n",
    "\n",
    "class FunctionCallsSignature(Signature):\n",
    "    functions: str = InputField(desc='The possible functions that can be called.')\n",
    "    history: str = InputField(desc='The conversation history that the function calls should be related to.')\n",
    "    calls: FunctionCall = OutputField(desc='A python code snippet that calls the necessary function.')\n",
    "    answer: str = OutputField(desc='The answer to the question.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0d6e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4:\n",
      "\n",
      "Turn 1: Can you update me on the top headlines from today's news? ---\n",
      "\n",
      "Turn 2: The function `get_latest_news` with parameters `category='general'`, `language='en'`, and `country='us'` has been called to fetch the top headlines from today's news.\n",
      "\n",
      "Turn 3: Could you summarize the main points from the first three headlines provided by the `get_latest_news` function? ---\n",
      "\n",
      "Turn 4: The main points from the first three headlines can be summarized once the `get_latest_news` function is called with the specified parameters and the articles are retrieved. However, summarizing the content is not a direct function call and would require additional processing of the returned list of news articles.\n",
      "\n",
      "Turn 5: Please proceed with the additional processing required to summarize the main points from the first three headlines returned by the `get_latest_news` function. ---\n",
      "\n",
      "Turn 6: To summarize the main points from the first three headlines returned by the `get_latest_news` function, we would first call the function to retrieve the latest news articles. After obtaining the list of articles, we would then need to extract the main points from each of the first three articles. This process is not covered by the existing functions and would likely involve natural language processing techniques to identify and extract key sentences or points from the article text.\n",
      "\n",
      "Function calls:\n",
      "('call', \"get_latest_news(category='general', language='en', country='us')\")\n",
      "('call', \"get_latest_news(category='general', language='en', country='us')\")\n",
      "('call', \"get_latest_news(category='general', language='en', country='us')\")\n",
      "name='get_latest_news' parameters={'category': 'string', 'language': 'string', 'country': 'string'} docstring='Fetches the latest news articles based on category, language, and country.' return_type='list'\n",
      "name='search_news' parameters={'query': 'string', 'page': 'int', 'page_size': 'int'} docstring='Searches for news articles based on a query string. Paginates results with page and page_size parameters.' return_type='list'\n",
      "name='get_trending_topics' parameters={'country': 'string', 'language': 'string'} docstring='Retrieves trending topics in news for a specific country and language.' return_type='list'\n",
      "name='get_news_sources' parameters={'category': 'string', 'language': 'string', 'country': 'string'} docstring='Lists all news sources available for a specific category, language, and country.' return_type='list'\n",
      "\n",
      "\n",
      "GPT-3.5-Turbo:\n",
      "\n",
      "Turn 1: What recent news story has caught your attention lately? ---\n",
      "\n",
      "Turn 2: {\n",
      "    \"call\": \"get_current_news()\"\n",
      "}\n",
      "\n",
      "Turn 3: What impact do you think this news story will have on society? ---\n",
      "\n",
      "Turn 4: {\n",
      "    \"calls\": {\n",
      "        \"call\": \"get_current_news()\"\n",
      "    },\n",
      "    \"answer\": \"The answer to the question.\"\n",
      "}\n",
      "\n",
      "Turn 5: What are your thoughts on how the media is covering this news story? ---\n",
      "\n",
      "Turn 6: {\n",
      "    \"calls\": {\n",
      "        \"call\": \"parse_news(news_article)\"\n",
      "    },\n",
      "    \"answer\": \"The answer to the question.\"\n",
      "}\n",
      "\n",
      "Function calls:\n",
      "('call', 'get_current_news()')\n",
      "('call', 'get_current_news()')\n",
      "('call', 'parse_news(news_article)')\n",
      "name='get_current_news' parameters={} docstring='Function to retrieve the current news from a news API' return_type='list of news articles'\n",
      "name='parse_news' parameters={'news_article': 'string'} docstring='Function to parse a news article and extract relevant information' return_type='dictionary'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from ersatz.interactions import GenerateQuestionOrInstruction\n",
    "\n",
    "class FunctionCallingConversation(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.question_instruction = dspy.Predict(GenerateQuestionOrInstruction)\n",
    "        self.get_functions = TypedPredictor(FunctionsSignature)\n",
    "        self.get_calls_answer = TypedPredictor(FunctionCallsSignature)\n",
    "    \n",
    "    def forward(self, topic, num_turns=1):\n",
    "        functions = [str(x) for x in self.get_functions(topic=topic).functions.functions]\n",
    "        initial = self.question_instruction(topic=topic, history=\"Empty\")\n",
    "        history = {\n",
    "            'conversation': [initial.question_or_instruction],\n",
    "            'function_calls': [],\n",
    "            'functions': functions\n",
    "        }\n",
    "        for i in range(num_turns):\n",
    "            response = self.get_calls_answer(functions='\\n-----\\n'.join(functions), history='\\n-----\\n'.join(history['conversation']))\n",
    "            history['conversation'].append(response.answer)\n",
    "            history['function_calls'].extend(response.calls)\n",
    "            if i < num_turns - 1:\n",
    "                query = self.question_instruction(topic=topic, history='\\n-----\\n'.join(history['conversation']))\n",
    "                history['conversation'].append(query.question_or_instruction)\n",
    "        \n",
    "        return history\n",
    "fc_conversation = FunctionCallingConversation()\n",
    "for lm_dict in lms:\n",
    "    lm, name = lm_dict[\"lm\"], lm_dict[\"name\"]\n",
    "    with dspy.context(lm=lm):\n",
    "        history = fc_conversation(\"current news\", num_turns=3)\n",
    "        print(f\"{name}:\\n\")\n",
    "        for i, turn in enumerate(history['conversation']):\n",
    "            print(f\"Turn {i + 1}: {turn}\\n\")\n",
    "        print(\"Function calls:\")\n",
    "        for call in history['function_calls']:\n",
    "            print(call)\n",
    "        for function in history['functions']:\n",
    "            print(function)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10471f7d-9f32-48c1-807f-936d19c1a87e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488448e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(\"abd('hello world')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abd(a):\n",
    "    \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570f836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
